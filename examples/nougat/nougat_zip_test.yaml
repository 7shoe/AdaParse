# This test case checks that we can parse zip files which contain multiple pdfs.

# The directory containing the pdfs to convert
pdf_dir: /lus/eagle/projects/FoundEpidem/braceal/projects/metric-rag/data/raw_pdfs/small_zip_test

# The output directory of the workflow
out_dir: /lus/eagle/projects/FoundEpidem/braceal/projects/metric-rag/data/parsed_pdfs/small_zip_test

# Search for zip files in the pdf_dir
iszip: true

parser_settings:
  name: nougat
  # Recommended batch size of pages (not pdfs) is 10, maximum that fits into A100 40GB.
  batchsize: 10
  # Path to download the checkpoint to. if already exists, will use existing.
  checkpoint: /lus/eagle/projects/CVD-Mol-AI/braceal/.cache/nougat/base
  # Set mmd_out to null if you don't want to write mmd files as a byproduct.
  mmd_out: null
  # If set to false, a will skip the pdfs that already have a parsed mmd file in mmd_out
  recompute: false
  # Set to true if you want to use fp32 instead of bfloat16 (false is recommended)
  full_precision: false
  # If set to true, output text will be formatted as a markdown file.
  markdown: true
  # Preempt processing a paper if mode collapse causes repetitions (true is recommended)
  skipping: true
  # Path for the nougat-specific logs for the run.
  nougat_logs_path: /lus/eagle/projects/FoundEpidem/braceal/projects/metric-rag/data/parsed_pdfs/small_zip_test/nougat_logs

# The compute settings for the workflow
compute_settings:
  # The name of the compute platform to use
  name: polaris
  # The number of compute nodes to use
  num_nodes: 1
  # Make sure to update the path to your conda environment and HF cache
  worker_init: "module load conda/2023-10-04; conda activate pdfwf"
  # The scheduler options to use when submitting jobs
  scheduler_options: "#PBS -l filesystems=home:eagle:grand"
  # Make sure to change the account to the account you want to charge
  account: FoundEpidem
  # The HPC queue to submit to
  queue: debug
  # The amount of time to request for your job
  walltime: "01:00:00"
